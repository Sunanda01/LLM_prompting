# 🧠 Prompt Engineering Techniques

A curated collection of prompt engineering strategies and techniques for working effectively with large language models (LLMs) such as GPT-4, Claude, and others.

> 📁 Organized into practical, real-world categories like summarizing, transforming, inferring, and more.

---

## 📂 Folder Structure

| Folder Name           | Description                                                                 |
|-----------------------|-----------------------------------------------------------------------------|
| `chatbot/`            | Prompts and patterns for building conversational agents and chatbots.       |
| `expanding/`          | Techniques for elaborating, extending ideas, or continuing content.         |
| `inferring/`          | Prompts designed to extract meaning, assumptions, or conclusions.           |
| `iterative_prompt/`   | Step-by-step refinement and feedback-based prompt workflows.                |
| `prompting_principle/`| Core principles and best practices of good prompt design.                   |
| `summarizing/`        | Strategies to condense long content into concise, useful summaries.         |
| `transforming/`       | Prompts for changing tone, format, style, or structure of a given input.    |

---

## 🧰 Use Cases

- 🔬 Research on prompt effectiveness
- 💡 Learning and teaching LLM behavior
- ✍️ Building LLM-powered applications
- 📚 Studying prompting principles and mechanics
- 🤖 Rapid prototyping for chatbots and assistants

---
